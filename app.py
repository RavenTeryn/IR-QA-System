import os
# --- 1. é…ç½®å›½å†…é•œåƒæº (å¿…é¡»æ”¾åœ¨æœ€å‰é¢) ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

import streamlit as st
import time
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- 2. é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(
    page_title="æ™ºèƒ½æ£€ç´¢é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ§ ",
    layout="wide"
)

# --- 3. è‡ªå®šä¹‰ CSS (è®©ç•Œé¢æ›´å¥½çœ‹) ---
st.markdown("""
<style>
    .reportview-container {
        background: #f0f2f6;
    }
    .main-header {
        font-size: 2.5rem;
        color: #4B4B4B;
        text-align: center;
        margin-bottom: 20px;
    }
    .source-card {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 10px;
        border-left: 5px solid #ff4b4b;
    }
    .answer-box {
        background-color: #e8f4f8;
        padding: 20px;
        border-radius: 10px;
        border: 1px solid #b8daff;
        margin-bottom: 20px;
    }
</style>
""", unsafe_allow_html=True)

# --- 4. æ ¸å¿ƒé€»è¾‘å‡½æ•° (å¸¦ç¼“å­˜) ---
@st.cache_resource
def initialize_system():
    # A. åŠ è½½æ¨¡å‹ (è¿™é‡Œä¸æ˜¾ç¤ºåŠ è½½æ–‡å­—ï¼Œè€Œæ˜¯é™é»˜åŠ è½½ï¼ŒçŠ¶æ€åœ¨ä¾§è¾¹æ æ˜¾ç¤º)
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    
    # B. è¯»å– data æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ txt æ–‡ä»¶
    loader = DirectoryLoader('data/', glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    documents = loader.load()
    if not documents:
        return None, None

    # C. åˆ‡åˆ†æ–‡æ¡£ (é’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–æ–­å¥)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,        
        chunk_overlap=50,      
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", "ã€", ""] 
    )
    splits = text_splitter.split_documents(documents)
    
    # D. å»ºç«‹å‘é‡ç´¢å¼•
    vector_db = FAISS.from_documents(splits, embeddings)
    
    return vector_db, documents

# --- 5. åˆå§‹åŒ–ç³»ç»Ÿ ---
with st.spinner("ç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ï¼Œæ„å»ºå‘é‡ç´¢å¼•ä¸­..."):
    vector_db, raw_docs = initialize_system()

# --- 6. ä¾§è¾¹æ å¸ƒå±€ (ç³»ç»ŸçŠ¶æ€ä¸æŠ€æœ¯æ ˆ) ---
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿæ§åˆ¶å°")
    
    # æŠ€æœ¯æ ˆè¯´æ˜ (æ›¿æ¢äº†åŸæ¥çš„Loadingæç¤º)
    st.markdown("### ğŸ› ï¸ æŠ€æœ¯æ¶æ„")
    st.info("**Embedding Model:**\n\nBAAI/bge-small-zh-v1.5 (æ™ºæºä¸­æ–‡è¯­ä¹‰å‘é‡)")
    st.info("**Vector Database:**\n\nFAISS (Facebook AI Similarity Search)")
    
    st.markdown("---")
    
    # çŸ¥è¯†åº“çŠ¶æ€
    st.markdown("### ğŸ“š çŸ¥è¯†åº“çŠ¶æ€")
    if raw_docs:
        st.success(f"âœ… å·²åŠ è½½æ–‡æ¡£æ•°: {len(raw_docs)}")
        with st.expander("æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"):
            for doc in raw_docs:
                file_name = doc.metadata['source'].split('/')[-1] if '/' in doc.metadata['source'] else doc.metadata['source']
                st.text(f"ğŸ“„ {file_name}")
    else:
        st.error("âš ï¸ æœªæ£€æµ‹åˆ°æ–‡æ¡£ï¼Œè¯·ä¸Šä¼  .txt æ–‡ä»¶")

# --- 7. ä¸»ç•Œé¢å¸ƒå±€ ---
st.markdown('<div class="main-header">ğŸ§  Retrieval-based QA System</div>', unsafe_allow_html=True)
st.markdown("<div style='text-align: center; color: grey;'>åŸºäº RAG æ¶æ„çš„ç»´åŸºç™¾ç§‘æ™ºèƒ½é—®ç­”ç³»ç»Ÿ</div>", unsafe_allow_html=True)
st.markdown("---")

# æœç´¢æ¡†åŒºåŸŸ
col1, col2 = st.columns([4, 1], vertical_alignment="bottom")
with col1:
    query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š", placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯GenAIï¼Ÿ")
with col2:
    search_btn = st.button("ğŸ” å¼€å§‹æ£€ç´¢", use_container_width=True)

# --- 8. æ£€ç´¢ä¸ç»“æœå±•ç¤º ---
if (query or search_btn) and vector_db:
    start_time = time.time()
    
    # æ ¸å¿ƒæ£€ç´¢æ­¥éª¤
    # k=4: è·å–æœ€ç›¸å…³çš„4ä¸ªç‰‡æ®µï¼Œç¬¬1ä¸ªä½œä¸ºç›´æ¥ç­”æ¡ˆï¼Œå3ä¸ªä½œä¸ºå‚è€ƒ
    results = vector_db.similarity_search(query, k=4)
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    
    # æ˜¾ç¤ºæ£€ç´¢ç»Ÿè®¡
    st.caption(f"ğŸš€ æ£€ç´¢å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.4f} ç§’")

    # A. æœ€ä½³ç­”æ¡ˆåŒºåŸŸ (Top 1 Result)
    st.markdown("### ğŸ’¡ æœ€ä½³åŒ¹é…ç­”æ¡ˆ (Best Answer Passage)")
    
    best_result = results[0]
    best_source = best_result.metadata['source']
    
    # ä½¿ç”¨è‡ªå®šä¹‰æ ·å¼çš„å®¹å™¨
    st.markdown(f"""
    <div class="answer-box">
        <p style="font-size: 1.1em; line-height: 1.6;">{best_result.page_content}</p>
        <hr style="border-top: 1px dashed #bbb;">
        <p style="color: #666; font-size: 0.9em;">ğŸ“ <strong>æ¥æºæ–‡æ¡£:</strong> {best_source}</p>
    </div>
    """, unsafe_allow_html=True)

    # B. æ›´å¤šç›¸å…³ä¸Šä¸‹æ–‡ (Context)
    with st.expander("ğŸ“– æŸ¥çœ‹æ›´å¤šç›¸å…³ä¸Šä¸‹æ–‡ (Supporting Context)"):
        for i, doc in enumerate(results[1:], 1):
            source_file = doc.metadata['source']
            st.markdown(f"""
            <div class="source-card">
                <p><strong>ç›¸å…³ç‰‡æ®µ {i}:</strong> {doc.page_content}</p>
                <p style="font-size: 0.8em; color: grey;">ğŸ“„ Source: {source_file}</p>
            </div>
            """, unsafe_allow_html=True)

elif not vector_db:
    st.warning("è¯·æ£€æŸ¥ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨ .txt æ–‡ä»¶ã€‚")